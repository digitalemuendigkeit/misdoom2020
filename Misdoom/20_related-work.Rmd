# Context
Since the commercialization of the internet, the relationship between digital media and political life has grown ever stronger. [@boulianneTwentyYearsDigital2018] Apart from election campaigns, one important facet is the internet's potential to strengthen democratic society by facilitating public deliberation. [@papacharissiVirtualSphereInternet2002; @chenOnlineIncivilityPublic2017] At the same time, several limitations for online public deliberation have emerged. For one, offline power imbalances are often mirrored in the online world through an overrepresentation of groups in power, e.g. well-educated white men. [@feezellPredictingOnlinePolitical2016] In addition, online groups tend to be very homogenous meaning that users are seldomly exposed to cross-cutting opinions or differing viewpoints. [@colleoniEchoChamberPublic2014] And when differing opinions do collide, incivility and even hate speech can occur. [@papacharissiDemocracyOnlineCivility2004; @coeOnlineUncivilPatterns2014; @rainsIncivilityPoliticalIdentity2017]

## Hate Speech and misinformation
Although hate speech has been at both discussed by the public at large as well as studied in academia, finding an universally valid definition has proved challenging. [@gagliardoneCounteringOnlineHate2015] Legal institutions and social networks alike tend to provide broad definitions that allow for judgement and possible sanctions on a case-by-case-basis. [@gagliardoneCounteringOnlineHate2015]

From a communication science perspective, @erjavecYouDonUnderstand2012 define hate speech as an expression that is in itself harmful or possibly harm-inciting and targets members of a group determined by characteristics like race or sexual orientation.  Similar characteristics can be found in other definitions that consider the purpose and the effects of hate speech: @waldronHarmHateSpeech2012 characterizes speech as hateful when it serves one or both of two functions: Firstly, to dehumanize a target group and diminish its members and secondly, to reinforce a sense of in-group with other like-minded individuals. Similarly, Susan Benesch has coined the term _dangerous speech_ which she defines as "[a]ny form of expression (e.g. speech, text, or images) that can increase the risk that its audience will condone or commit violence against members of another group." [@beneschDangerousSpeechPractical2020] Often, the groups targeted are marginalized social group. [@alvarez-benjumeaNormativeChangeCulture2018] But especially in common parlance, hate speech can also describe speech directed at groups like politicians that are arguably powerful. [@gagliardoneCounteringOnlineHate2015] In summary, hate speech both reenforces the boundaries between groups and is harmful in itself or in its effects to members of the other group.

Hate speech is inextricably linked to disinformation. For one, online hate often takes the form of over-generalization, exaggeration or even outright deceit about the targeted group. E.g., @awanIslamophobiaSocialMedia2016 stresses the use of false stories to exacerbate islamophobic hate. For another, disinformation like fake news often serve the same purpose as hate speech: Polarization, radicalization and othering of the out-group. [@bennettDisinformationOrderDisruptive2018]

There is ample evidence for the damaging effects of hate speech, not only on the victim of the hate speech but also on the broader audience. Constant exposition shapes users worldview and influences their decisio-making [@jubanyBackgroundsExperiencesResponses2016; @erjavecReadersOnlineNews2014] Reading hateful and uncivil content increases attitude polarization.  [@borahDoesItMatter2014; @kimIncivilityFacebookPolitical2019] And by inducing negative emotions, it can also discourage people from engaging in discourse. [@hwangDoesCivilityMatter22; @hwangSeeingBelievingEffects2014; @kimIncivilityFacebookPolitical2019; @molinaRoleCivilityMetacommunication2018] Thereby, it actively impedes on the internet's potential for public deliberation.

One possible way to counter hate speech is counter speech. Counter speech can be defined as a dissenting response to hate speech. [@wrightVectorsCounterspeechTwitter2017] Although it is sometimes used in a way that also encompasses actions like flagging hateful content, our study focusses on counter speech in the form of content, e.g. comments in answer to the original post.

## Effectiveness of Counter Speech
Counter speaking is encouraged in many anti-hate speech programs. [@gagliardoneCounteringOnlineHate2015] Furthermore, scholars like [@chenOnlineIncivilityPublic2017] argue that countering online incivility is necessary to realize the potential of online spaces as a place for political deliberation. In spite of that, only a few studies have actually evaluated the effectiveness of counter speech. @buergerCounterspeechLiteratureReview2019 have reviewed the studies available in November 2019. They differentiate between the effects of counter speech on the hateful speaker and the effects on the wider audience.

Concerning the effects of counter speech on the hateful speaker, the studies listed have produced inconclusive results. [@buergerCounterspeechLiteratureReview2019] However, there is some evidence that counter speech by users perceived as more influential can curb hate speech at least temporarily (e.g.[@mungerTweetmentEffectsTweeted2017]).
Findings on the effects of counter speech on the wider audience are less ambiguous. They all find evidence for something that @buergerCounterspeechLiteratureReview2019 call "contagion effect", i.e., the presence of hateful comments increases the probability of an user also making a hateful comment, but the opposite is also true. Moreover, meta-comments urging people to be civil promote further meta-comments about discussion quality. [@molinaRoleCivilityMetacommunication2018]

Moreover, with the sheer volume of content being generated on social networking platforms like Facebook or Twitter, those sites rely on their users in their fight against hate speech. Users have to flag possibly unwanted content in order for it to be reviewed by moderators. [@heldtLetMeetHalfway2020; @gagliardoneCounteringOnlineHate2015] Arguably, flagging content is a less involved action than verbally confronting a perpetrator. But it still relies on users assuming responsibility. So while further research on the effects of counter speech is desirable, the existing indications for its success prompts us to ask what predicts users engaging in counter speech.

## Predictors for Counter Speech
There already exist several studies examining willingness to intervene against hate speech and incivility in general and even more studies from the field of cyber-bystander research @lambeStandingBullyingSocial2019 extensively reviewed studies on bullying and peer defending. As bystander intervention in (cyber-)bullying is similar to counter speech, predictors from those studies are included as well.

The following predictors refer to intervention intention, with intervention ranging from more distanced behavior like using the reporting function (e.g. [@wongCombatingOnlineAbuse2016]) to deeply involved behavior like verbally confronting the individual engaging in hate speech (e.g. [@dickterConfrontNotConfront2013]). 

* Individual factors:
    + Female gender, [@lambeStandingBullyingSocial2019; @wilhelmGenderedMoralityBacklash2019]
    + high prosociality and empathy, [@lambeStandingBullyingSocial2019]
    + high self-efficacy, [@lambeStandingBullyingSocial2019]
    + negative attitude towards passive bystanding, [@lambeStandingBullyingSocial2019]
    + expectation that defending will help, [@lambeStandingBullyingSocial2019],
    + low moral disengagement, high moral identity scores and individualizing moral foundation, [@lambeStandingBullyingSocial2019; @wilhelmGenderedMoralityBacklash2019]
    + negative affect, [@chenOnlineIncivilityPublic2017; @dickterConfrontingHateHeterosexuals2012; @dickterConfrontNotConfront2013] and
    + perceived social pressure and responsibility. [@dickterConfrontingHateHeterosexuals2012; @dickterConfrontNotConfront2013; @wongCombatingOnlineAbuse2016]
    
* Properties of the victim, relationship to and attitudes towards victim:
    + Individual person as a victim, not abstract social group,  [@naabFlaggingUncivilUser2018]
    + higher popularity of the victim, [@lambeStandingBullyingSocial2019]
    + friendship or positive relationship with victim, [@lambeStandingBullyingSocial2019] and
    + low level of prejudice towards victims's social group. [@dickterConfrontingHateHeterosexuals2012]
    
* Situational factors:
    + Increased deviance of the situation, [@dickterConfrontingHateHeterosexuals2012; @dickterConfrontNotConfront2013; @naabFlaggingUncivilUser2018]
    + more than one perpetrator, and [@kazerooniCyberbullyingBystanderIntervention2018]
    + more steps of the bystander intervention model are met (situation is noticed, fewer number of bystanders, information on how to confront is provided), [@lambeStandingBullyingSocial2019; @naabFlaggingUncivilUser2018].
    
To summarize, the existing research on hate speech intervention mainly considers the properties of the would-be counter speaker. For this study, we wanted to further research on hate speech intervention by focussing in the relationships between the would-be counter speaker and the victim. To be precise, with hate speech as an instrument for social division and polarization, can counter speech bridge the gap between in- and out-group? Therefore, our research question is:

*In social media discussions, what are predictors for users to engage in counter speech in support of political adversaries?*